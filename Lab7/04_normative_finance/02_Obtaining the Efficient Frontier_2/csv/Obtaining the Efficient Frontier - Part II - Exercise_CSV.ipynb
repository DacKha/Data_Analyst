{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Efficient Frontier - Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Suggested Answers follow (usually there are multiple ways to solve a problem in Python).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let’s continue the exercise from the last lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already downloaded the data and generated two random weightings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG</th>\n",
       "      <th>^GSPC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>61.119999</td>\n",
       "      <td>1132.989990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>61.139999</td>\n",
       "      <td>1136.520020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>60.849998</td>\n",
       "      <td>1137.140015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>60.520000</td>\n",
       "      <td>1141.689941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>60.439999</td>\n",
       "      <td>1144.979980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-20</th>\n",
       "      <td>91.220001</td>\n",
       "      <td>2373.469971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-21</th>\n",
       "      <td>91.190002</td>\n",
       "      <td>2344.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-22</th>\n",
       "      <td>90.989998</td>\n",
       "      <td>2348.449951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-23</th>\n",
       "      <td>90.769997</td>\n",
       "      <td>2345.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-24</th>\n",
       "      <td>90.570000</td>\n",
       "      <td>2343.979980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PG        ^GSPC\n",
       "Date                              \n",
       "2010-01-04  61.119999  1132.989990\n",
       "2010-01-05  61.139999  1136.520020\n",
       "2010-01-06  60.849998  1137.140015\n",
       "2010-01-07  60.520000  1141.689941\n",
       "2010-01-08  60.439999  1144.979980\n",
       "...               ...          ...\n",
       "2017-03-20  91.220001  2373.469971\n",
       "2017-03-21  91.190002  2344.020020\n",
       "2017-03-22  90.989998  2348.449951\n",
       "2017-03-23  90.769997  2345.959961\n",
       "2017-03-24  90.570000  2343.979980\n",
       "\n",
       "[1819 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load data from CSV\n",
    "pf_data = pd.read_csv('Markowitz_Data.csv', index_col='Date')\n",
    "\n",
    "# Define assets based on available data\n",
    "assets = list(pf_data.columns)\n",
    "pf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94930294, 0.05069706])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_returns = np.log(pf_data / pf_data.shift(1))\n",
    "\n",
    "num_assets = len(assets)\n",
    "\n",
    "weights = np.random.random(num_assets)\n",
    "weights /= np.sum(weights)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, estimate the expected Portfolio Return, Variance, and Volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Portfolio Return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05640839256506687"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate expected portfolio return\n",
    "# Formula: weights × mean returns × 250 (annualization factor)\n",
    "pf_return = np.sum(weights * log_returns.mean()) * 250\n",
    "pf_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Portfolio Variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019718281818215024"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate expected portfolio variance\n",
    "# Formula: weights.T × covariance matrix × weights × 250\n",
    "pf_variance = np.dot(weights.T, np.dot(log_returns.cov() * 250, weights))\n",
    "pf_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Portfolio Volatility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1404217996545231"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate expected portfolio volatility\n",
    "# Formula: square root of variance\n",
    "pf_volatility = pf_variance ** 0.5\n",
    "pf_volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this exercise will be a reproduction of what we did in the previous video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\tCreate two empty lists. Name them pf_returns and pf_volatilites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create empty lists for portfolio returns and volatilities\n",
    "pf_returns = []\n",
    "pf_volatilities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\tCreate a loop with 1,000 iterations that will generate random weights, summing to 1, and will append the obtained values for the portfolio returns and the portfolio volatilities to pf_returns and pf_volatilities, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000 random portfolios\n"
     ]
    }
   ],
   "source": [
    "# Loop 1000 times to generate random portfolios\n",
    "for x in range(1000):\n",
    "    # Generate random weights\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    # Calculate portfolio return and variance\n",
    "    pf_returns.append(np.sum(weights * log_returns.mean()) * 250)\n",
    "    pf_volatilities.append(np.sqrt(np.dot(weights.T, np.dot(log_returns.cov() * 250, weights))))\n",
    "\n",
    "print(\"Generated 1000 random portfolios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\tTransform the obtained lists into NumPy arrays and reassign them to pf_returns and pf_volatilites. Once you have done that, the two objects will be NumPy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns shape: (1000,)\n",
      "Volatilities shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "pf_returns = np.array(pf_returns)\n",
    "pf_volatilities = np.array(pf_volatilities)\n",
    "\n",
    "print(\"Returns shape:\", pf_returns.shape)\n",
    "print(\"Volatilities shape:\", pf_volatilities.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
